---
title: "multivariate brms for F1 and F2"
author: "Xinyu Zhang"
date: "2024-27-12"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
# Basic settings (just trust me on this :P)
options(scipen = 99999) 
options(mc.cores=2) 
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, cache=TRUE)
options(tinytex.verbose = TRUE)
```

# Reading in data

```{r}
df <- read.csv("productionFullTable.csv")


#change variables into correct data types
df$BB <- as.factor(df$BB)
df$Label <- as.factor(df$Label)
df$block <- as.factor(df$block)
df$gender <- as.factor(df$gender)
df$AF <- as.factor(df$AF)
df$subj <- as.character(df$subj)
df$seq <- as.numeric(df$seq)
df$F0Hz <- as.numeric(df$F0Hz)
df$F1Hz <- as.numeric(df$F1Hz)
df$F2Hz <- as.numeric(df$F2Hz)
df$F1Bark <- as.numeric(df$F1Bark)
df$F2Bark <- as.numeric(df$F2Bark)

#coding the reference level for contrasts
df$BB <- relevel(df$BB, ref = "NB") #non-bite-block group as reference 

df$AF <- relevel(df$AF, ref = "AF") #regular auditory feedback group as reference

df$Label <- relevel(df$Label, ref = "E") #vowel /E/ as reference because it is less affected by the bite block

df$block <- relevel(df$block, ref = "1") #block 1 as reference because it's the pretest

gender.contrast <- cbind (c (-0.5, +0.5)) # female = -0.5, male = +0.5 
colnames (gender.contrast) <- c ("-F+M")
contrasts (df$gender) <- gender.contrast #it makes more sense to have the grand mean as reference level than having either gender. See the other html file for comparison


#showing the structure of the data table
library(dplyr)
summary(df)
```

# Basic multivariate

```{r}
library(brms)

mult1 <- bf(mvbind(F1Hz, F2Hz) ~ block * BB * AF* Label + gender + (1|p|subj) + (1|q|word)) + set_rescor(TRUE)

# "|p|" in between indicates that all varying effects of `subj` should be modeled as correlated (F1&F2 intercept per subject). Same with "|q|".

# "set_rescor=(TRUE)" indicates that the errors of F1 and F2 estimates are to be modeled as correlated

fit1 <- brm(mult1, data = df, chains = 2, cores = 2, seed = 206) #setting seed for reproducibility
```

# summarizing the results

```{r}
fit1 <- add_criterion(fit1, "loo")
summary(fit1)
```

# posterior predictive check

```{r}
pp_check(fit1, resp = "F1Hz")

pp_check(fit1, resp = "F2Hz")
```

The fit looks good, with a little bit of unmodeled left skewness of the distribution of F1.

# Check $R^2$

```{r}
bayes_R2(fit1)
```

The R squared looks really good :)

# using an ex-Gaussian distribution as family instead of Gaussian

* (Gamma failed)
* (ex-gaussian did not mix at default iterations, changing the iteration count to 3000 or 4000 did not help)
```{r}
mult2 <- bf(mvbind(F1Hz, F2Hz) ~ block * BB * AF* Label + gender + (1|p|subj) + (1|q|word)) #set_rescor(TRUE) is not possible for exgaussian

fit2 <- brm(mult2, data = df,family = exgaussian(link = "identity", link_sigma = "log", link_beta = "log"), chains = 2, cores = 2, iter = 4000)
```

```{r}
fit2 <- add_criterion(fit2, "loo")
summary(fit2)
```

R-hat is all bad, Bulk- and Tail-ESS are all too low.


Try adding priors to the first model instead


First let's get the priors that the first model ended up using.

```{r}
get_prior(fit1)
```


For the F1 intercept, the first model (fit1) used the prior `student_t(3,493,111.2)`. 

Meaning a student_t distribution with: 

degree of freedom (\nu) = 3, location(\mu) = 493, and SD (\sigma) = 111.2

## Trying to set a prior for a higher \sigma, so that we allow a wider peak in the distribution, 

and hopefully reduce the skewness in the fit

```{r}
mult1 <- bf(mvbind(F1Hz, F2Hz) ~ block * BB * AF* Label + gender + (1|p|subj) + (1|q|word)) + set_rescor(TRUE) #same as the first model
fit3 <- brm(mult1, data = df, 
            prior = set_prior("student_t(3, 0, 250)", class = "sd", resp = "F1Hz", group = "subj", coef = "Intercept"),
            chains = 2, cores = 2, seed = 655)
summary(fit3)
```

Doing a new pp_check
```{r}
pp_check(fit3, resp = "F1Hz")

pp_check(fit3, resp = "F2Hz")
```

I do not see much difference in the fit from the first model with flat priors.

Checking R^2
```{r}
bayes_R2(fit3)
```

R^2 did not improve.

Trying a different family with the prior included

```{r}
fit4 <- brm(mult2, data = df,family = exgaussian(link = "identity", link_sigma = "log", link_beta = "log"),
            prior = set_prior("student_t(3, 0, 250)", class = "sd", resp = "F1Hz", group = "subj", coef = "Intercept"),
             chains = 2, cores = 2, iter = 4000)


summary(fit4)
```

The R-hat and the bulk_ESS do not look good enough for the results to be reliable.

new pp check:

```{r}
pp_check(fit4, resp = "F1Hz")

pp_check(fit4, resp = "F2Hz")
```

The F1 fit looks a bit better (but it's unreliable anyway). but F2 is worse.

## Trying to set a prior for the median in F1, according to data from Adank (2004), averaged across genders at 505Hz (because of the -0.5/+0.5 contrast coding here), which is not too different from the 493 in my data. (But still keeping the default family and default iteration count)

```{r}
fit5 <- brm(mult2, data = df,
            prior = set_prior("student_t(3, 505, 250)", class = "Intercept", resp = "F1Hz"),
            chains = 2, cores = 2)
summary(fit5)
```

pp check

```{r}
pp_check(fit5, resp = "F1Hz")

pp_check(fit5, resp = "F2Hz")
```